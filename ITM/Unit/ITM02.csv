Kurs|Thema|Frage|Hinweis_1|Hinweis_2|Antwort|Extra|Real_World_Case|Mnemonik|MC_Richtig|MC_Falsch1|MC_Falsch2|MC_Falsch3|Schlagwörter
Bachelor Professional IT|Virtualisierung Grundlagen|Was versteht man technisch unter "Virtualisierung" und welche zentrale Funktion übernimmt der dabei eingesetzte "Abstraktions-Layer"?|Entkopplung|Physisch zu Logisch|Virtualisierung ist die <b>Nachbildung eines Hard- oder Software-Objekts</b> durch ein ähnliches Objekt desselben Typs.<br>- Der <b>Abstraktions-Layer</b> (oft Hypervisor) wandelt dabei physische Ressourcen (CPU, RAM) in <b>logische Einheiten</b> um.<br>- Dies ermöglicht den Betrieb mehrerer isolierter Instanzen auf einer Hardware.|Ohne diesen Layer wäre ein Betriebssystem fest an die Hardware "gekettet". Die Virtualisierung sprengt diese Kette und macht die VM zu einer portablen Datei. Das Gegenteil ist "Bare Metal".|Ein physischer Server mit 64 Kernen wird durch den Layer in 10 virtuelle Server mit je 6 Kernen aufgeteilt.|Virtual = Scheinbar (aber nutzbar)|Nachbildung von Objekten; Umwandlung physischer in logische Ressourcen.|Die physische Verschmelzung von zwei Festplatten zu einer.|Die reine Emulation alter Spielkonsolen auf dem PC.|Die Erhöhung der Taktfrequenz der CPU durch Software.|Virtualisierung Definition Abstraktion Layer
Bachelor Professional IT|Ziele der Virtualisierung|Welche drei primären betriebswirtschaftlichen und technischen Ziele werden durch den Einsatz von Virtualisierung (laut Definition) verfolgt?|Green IT & Kosten|Effizienz-Dreieck|Die Hauptziele sind:<br>1. <b>Bessere Hardwareauslastung</b> durch Konsolidierung (Vermeidung von Leerlauf).<br>2. <b>Erhöhung der Ausfallsicherheit</b> (schnelles Verschieben von VMs bei Defekten).<br>3. <b>Senkung von Kosten</b> und Stromverbrauch (weniger physische Geräte nötig).|Früher lief ein Server oft bei 5-10% Last ("Idle"). Durch Virtualisierung nähert man sich 70-80%, was den ROI (Return on Invest) massiv verbessert.|Statt 10 Servern mit je 10% Last betreibt man 2 Server mit je 50% Last und spart 8-mal Hardware und Strom.|Konsolidierung = Zusammenfassung|Höhere Auslastung (Konsolidierung), Ausfallsicherheit und Kostensenkung.|Erhöhung der Hardware-Preise, mehr Personalbedarf, langsamere Systeme.|Abschaffung aller physischen Server, Nutzung von reinem WLAN.|Nur die Nutzung für Software-Tests.|Virtualisierung Vorteile Konsolidierung Kosten
Bachelor Professional IT|Infrastruktur-Planung|Sie sollen für eine Bank eine hochperformante Server-Farm planen, auf der 200 virtuelle Server laufen sollen. Welches Produkt/Technologie wählen Sie zwingend aus?|Produktkenntnis|Enterprise-Lösung|Zwingend einen <b>Typ-1 Hypervisor</b> (z. B. VMware ESXi, Microsoft Hyper-V Server, Citrix XenServer).<br>Gründe:<br>- Direkter Hardwarezugriff für maximale I/O-Leistung.<br>- Stabilität (kein Host-OS, das abstürzen oder Updates laden muss).<br>- Zertifizierung für Enterprise-Workloads.|In der Prüfung müssen Sie oft Produkte den Kategorien zuordnen. ESXi ist der Industriestandard für Typ-1. VirtualBox ist ein klassisches Typ-2 Tool für den Desktop.|Keine Bank betreibt ihr Core-Banking auf einem Windows-PC mit VirtualBox.|Typ-1 = Bank, Typ-2 = Bastler|VMware vSphere ESXi oder Microsoft Hyper-V Server (Typ-1).|Oracle VirtualBox (Typ-2).|Parallels Desktop (Typ-2).|VMware Workstation Player (Typ-2).|Szenario Auswahl Hypervisor ESXi Hyper-V
Bachelor Professional IT|Hypervisor-Konzepte|Was ist das entscheidende Merkmal der <b>Paravirtualisierung</b> im Gegensatz zur vollständigen Hardware-Virtualisierung in Bezug auf das Gast-Betriebssystem?|Kooperation statt Emulation|Anpassung nötig|Bei der <b>Paravirtualisierung</b> muss das Gast-Betriebssystem <b>modifiziert</b> (angepasst) werden.<br>- Grund: Das Gast-OS "weiß", dass es virtualisiert ist, und kommuniziert über spezielle Schnittstellen (Hypercalls) direkt mit dem Hypervisor, statt Hardware treiberseitig zu emulieren.<br>- Vorteil: Höhere Performance durch geringeren Overhead.|Im Gegensatz dazu gaukelt die Vollvirtualisierung dem Gast eine komplette Hardware vor (Gast ist unmodifiziert). Moderne CPUs unterstützen dies heute hardwareseitig (VT-x/AMD-V), sodass Paravirtualisierung seltener manuell nötig ist.|Xen nutzte früher Paravirtualisierung für Linux-Gäste, um schneller zu sein als die reine Emulation.|Para = Daneben/Angepasst|Das Gast-Betriebssystem muss modifiziert (angepasst) werden.|Das Gast-System läuft komplett isoliert ohne Wissen über die Virtualisierung.|Das Gast-System muss ein Windows-System sein.|Der Hypervisor wird im Gast-System installiert.|Virtualisierung Paravirtualisierung Hypervisor Gast-OS
Bachelor Professional IT|Betriebssystem-Virtualisierung|Wie erzeugt die <b>Betriebssystem-Virtualisierung</b> (z. B. Solaris Container, FreeBSD Jails) ihre Instanzen und worin liegt der architektonische Unterschied zur Hypervisor-Lösung?|Kernel-Sharing|Container-Prinzip|Bei der <b>OS-Virtualisierung</b> erzeugt der <b>Kernel</b> des Host-Systems mehrere isolierte Umgebungen (User-Spaces).<br>- Unterschied: Alle Instanzen teilen sich den <b>gleichen Kernel</b> (Shared Kernel). Es gibt keinen Hypervisor und keine virtuellen Hardware-Treiber für jede Instanz.<br>- Vorteil: Extrem geringer Ressourcenverbrauch (Overhead).|Dies ist der Vorläufer und das Prinzip von Docker. Während eine VM (Hypervisor) Minuten zum Booten braucht (eigener Kernel startet), startet ein Container (OS-Virt) in Millisekunden (Prozess im laufenden Kernel startet).|FreeBSD Jails oder Docker-Container auf Linux.|OS-Virt = 1 Kernel, viele User|Der Host-Kernel erzeugt isolierte User-Space-Umgebungen (Shared Kernel).|Sie nutzt für jede Instanz einen eigenen Kernel auf eigener virtueller Hardware.|Sie partitioniert die Festplatte physisch in zwei Hälften.|Sie emuliert für jeden Container eine eigene CPU.|Virtualisierung Container OS-Virtualisierung Kernel
Bachelor Professional IT|Server-Virtualisierung Ebenen|Ein Kunde fordert für sein Hochsicherheits-Rechenzentrum eine strikte Trennung der Systeme. Es darf keine gemeinsame Software-Schicht (Hypervisor) geben, aber die Hardware (Baugruppen) soll in einem einzigen Schrank (Rack/Chassis) verbaut sein. Welche Ebene der Abstraktion ist hier gefordert?|Hard-Isolation|Kein Shared Code|<b>Physische Partitionierung</b>.<br>Hierbei werden die zugrunde liegenden <b>realen Baugruppen</b> (CPUs, RAM-Bänke, I/O-Karten) elektrisch/physisch in separate Partitionen getrennt.<br>- Es gibt keinen gemeinsamen Hypervisor, der als Single Point of Failure oder Angriffsfläche dienen könnte.|Dies ist die stärkste Form der Isolation innerhalb eines Systems, oft bei Mainframes (IBM Z) oder großen UNIX-Servern zu finden. Jede Partition hat ihre eigene "echte" Hardware.|LPARs (Logical Partitions) bei IBM Mainframes, die hardwareseitig getrennt sind.|Physisch = Hart getrennt|Physische Partitionierung (Hardware-Trennung).|Hypervisor-basierende Virtualisierung.|Betriebssystem-Virtualisierung (Container).|Virtualisierung im Trägerbetriebssystem.|Virtualisierung Partitionierung Hardware Sicherheit
Bachelor Professional IT|Speicher-Virtualisierung|Was ist das technische Kernziel der <b>Speicher-Virtualisierung</b> und welchen direkten administrativen Vorteil bietet sie laut Definition?|Entkopplung|Logik vs. Physik|<b>Speicher-Virtualisierung</b> ist die Technik zur <b>Abstraktion physischer Speichereigenschaften</b>.<br>- Ziel: Verwaltung von Speicher <b>unabhängig von physischen Grenzen</b> (z. B. Festplattengröße).<br>- Vorteil: Der Nutzer sieht einen virtuellen Pool, was den <b>Auslastungsgrad</b> erhöht und Erweiterungen vereinfacht.|Ohne Virtualisierung ist eine 1TB-Festplatte voll, wenn 1TB Daten drauf sind. Mit Virtualisierung können Sie einem Server 5TB "vorgaukeln" (Thin Provisioning) und physischen Speicher erst nachkaufen, wenn er wirklich gebraucht wird.|Ein Server "sieht" ein 10TB Laufwerk, das physisch aber auf drei verschiedenen Storage-Boxen verteilt liegt.|Virtuell = Schein (aber nutzbar)|Abstraktion physischer Grenzen; höhere Auslastung und einfachere Erweiterung.|Die Komprimierung von Daten, um Festplattenplatz zu sparen.|Die Umwandlung von Arbeitsspeicher (RAM) in Festplattenspeicher.|Die physische Verschmelzung von Kabeln zur Reduzierung von Kabelsalat.|Storage Virtualisierung Definition Pool Management
Bachelor Professional IT|Virtualisierungs-Ansätze (Storage)|Wie unterscheiden sich <b>In-Band</b> und <b>Out-Band</b> Virtualisierung hinsichtlich der Führung von Daten- und Kontrollfluss?|Architektur-Pfad|Bottleneck-Frage|Der Unterschied liegt im Pfad:<br>1. <b>In-Band</b>: Daten- und Kontrollfluss laufen über den <b>selben Pfad</b>. Das System sitzt "mitten im Datenstrom" und leitet jeden IO weiter (Gefahr: Latenz/Flaschenhals).<br>2. <b>Out-Band</b>: Daten- und Kontrollfluss sind <b>getrennt</b>. Die Virtualisierung (Metadaten) erfolgt oft in Switches, die eigentlichen Nutzdaten fließen direkt zum Speicher.|In-Band ist oft einfacher zu implementieren (Appliance dazwischenschalten), aber schwerer zu skalieren. Out-Band ist performanter, da der "Verwalter" den Datenstrom nicht bremst, aber komplexer zu konfigurieren (Agenten nötig).|In-Band: Pförtner, der jedes Paket kontrolliert. Out-Band: Pförtner gibt nur den Wegweiser, Paket geht direkt durch.|In = Mitten drin, Out = Draußen|In-Band = Gleicher Pfad (alles durch das System); Out-Band = Getrennte Pfade (Split-Path).|In-Band nutzt WLAN, Out-Band nutzt Kabel.|Bei Out-Band laufen Daten und Kontrolle über denselben Pfad.|In-Band ist nur für Backups, Out-Band für Live-Daten.|Storage In-Band Out-Band Architektur Performance
Bachelor Professional IT|Storage-Management Szenario|Ein Unternehmen besitzt Storage-Systeme von drei verschiedenen Herstellern (EMC, NetApp, HP). Der Admin möchte diese isolierten Inseln zu einem einzigen, großen Speicherpool zusammenfassen, um Kapazitäten flexibel zwischen den Abteilungen zu verschieben. Welches Konzept ermöglicht dies?|Pooling|Silo-Auflösung|Die <b>Speicher-Virtualisierung</b>.<br>Sie schiebt sich als Abstraktionsschicht vor die physischen Geräte verschiedener Hersteller und präsentiert sie nach oben als einen homogenen <b>virtuellen Speicherpool</b>.|Dies verhindert "Storage-Silos" (wo System A voll ist und System B leer, aber man den Platz nicht nutzen kann). Die Software übernimmt die Zuweisung auf die physischen Medien im Hintergrund.|IBM SVC (SAN Volume Controller) ist ein klassisches Beispiel, das verschiedene Storage-Boxen "virtualisiert".|Virtualisierung = Ein Pool für alle|Speicher-Virtualisierung (Abstraktion der Hardware).|RAID 5 (Striping mit Parität).|Deduplizierung (Datenreduktion).|Physische Partitionierung (Hardware-Trennung).|Szenario Storage Pool Heterogen Virtualisierung
Bachelor Professional IT|Speicher-Virtualisierung|Was ist die primäre Funktion einer <b>Virtualisierungs-Appliance</b> im Storage-Umfeld und was ermöglicht sie dem Administrator?|Management-Ebene|Zentralisierung|Eine <b>Virtualisierungs-Appliance</b> (Hardware oder Software) ermöglicht die <b>zentrale Verwaltung aller Speicherbereiche</b>.<br>- Sie schaltet sich vor die physischen Speichergeräte.<br>- Funktion: Sie fasst verteilte Ressourcen zu einem Pool zusammen, den der Admin zentral steuern kann, ohne jede einzelne Festplatte anfassen zu müssen.|Ohne Appliance müssten Sie 10 verschiedene Storage-Boxen einzeln konfigurieren (Silos). Mit Appliance haben Sie *ein* Dashboard für Petabytes an Daten.|SVC (SAN Volume Controller) von IBM ist eine typische Appliance.|Appliance = Zentraler Manager|Zentrale Verwaltung aller Speicherbereiche (Pooling) als logische Einheit.|Sie dient nur als Virenscanner für Festplatten.|Sie ist ein passives Kabel zur Verbindung von Servern.|Sie ersetzt die Festplatten durch RAM-Bausteine.|Storage Virtualisierung Appliance Definition Management
Bachelor Professional IT|Hochverfügbarkeit (HA)|In welcher technischen Betriebsart wird eine Virtualisierungs-Appliance idealerweise ausgeführt, um Ausfallsicherheit zu garantieren, und welche zwei Modi sind dabei üblich?|Redundanz-Konzepte|Aktiv/Passiv vs. Aktiv/Aktiv|Sie wird als <b>Cluster</b> ausgeführt.<br>Zwei Hauptmodi:<br>1. <b>Failover-Cluster</b> (Aktiv/Passiv): Ein Knoten arbeitet, der andere springt nur bei Ausfall ein.<br>2. <b>Load-Balancing-Cluster</b> (Aktiv/Aktiv): Beide Knoten arbeiten und teilen sich die Last (höhere Performance).|Ein Storage-Controller darf niemals alleine sein. Fällt er aus, sind alle Daten unerreichbar (obwohl die Platten noch heil sind). Cluster verhindern diesen "Brain-Dead"-Zustand.|Fällt Node A aus, übernimmt Node B sofort die I/O-Anfragen (Failover).|Cluster = Teamarbeit|Als Cluster (Failover für Sicherheit oder Load-Balancing für Lastverteilung).|Als Standalone-Gerät (Einzelsystem).|Als Daisy-Chain (Reihenschaltung ohne Redundanz).|Als Peer-to-Peer Netzwerk (jeder mit jedem).|Cluster Failover Load-Balancing Hochverfügbarkeit
Bachelor Professional IT|RZ-Sicherheit & Planung|Ein Kunde fordert "maximale Sicherheit" gegen physische Katastrophen (z. B. Feuer) für seine Storage-Virtualisierung. Wie muss der Cluster räumlich und logisch konfiguriert sein?|Physischer Schutz|Metro-Cluster Prinzip|Die Lösung erfordert zwei Maßnahmen:<br>1. <b>Räumlich</b>: Verteilung der Cluster-Knoten auf <b>zwei getrennte Brandabschnitte</b> (oder Rechenzentren).<br>2. <b>Logisch</b>: Einsatz von <b>RAID 1 (Spiegelung)</b> über diese Distanz hinweg (Synchronspiegel).|Brennt es in Abschnitt A, läuft der Betrieb in Abschnitt B nahtlos weiter, da dort eine exakte 1:1 Kopie der Daten liegt und der dortige Cluster-Knoten übernimmt. Dies nennt man oft "Metro-Cluster".|Brandabschnitt A (Serverraum 1) <-> Glasfaser <-> Brandabschnitt B (Serverraum 2).|Getrennte Räume + RAID 1|Verteilung auf zwei Brandabschnitte + synchrone Spiegelung (RAID 1).|Alles in einem Rack, gesichert durch RAID 0.|Verteilung auf zwei Etagen im selben Brandabschnitt.|Nur Backup auf Bändern im Keller.|Sicherheit Brandabschnitt RAID1 Disaster-Recovery
Bachelor Professional IT|Desktop-Virtualisierung (VDI)|Worin liegt der entscheidende architektonische Unterschied zwischen <b>VDI (Virtual Desktop Infrastructure)</b> und <b>SBC (Server Based Computing)</b> in Bezug auf das Betriebssystem?|1:1 vs. 1:N|Isolation|Der Unterschied ist das Verhältnis User-zu-OS:<br>1. <b>VDI</b>: Jeder User hat seine <b>eigene virtuelle Maschine</b> (z. B. Windows 11). Probleme (Blue Screen) betreffen nur diesen einen User.<br>2. <b>SBC (Terminal Server)</b>: Viele User arbeiten gleichzeitig auf <b>demselben Server-Betriebssystem</b>. Ein Absturz reißt alle mit.|VDI bietet die maximale Isolation und Performance (da Ressourcen nicht dynamisch geteilt werden müssen wie bei SBC). Dafür ist der Speicherbedarf riesig (100 User = 100 Windows-Installationen).|SBC ist der Bus (alle in einem Fahrzeug), VDI ist die Taxi-Flotte (jeder im eigenen Auto).|VDI = Eigener PC im RZ|VDI = 1 User pro OS (Iso); SBC = Viele User auf 1 Server-OS (Shared).|Bei VDI teilen sich alle User ein Server-OS; bei SBC hat jeder sein eigenes.|VDI läuft nur lokal auf dem PC; SBC läuft im Rechenzentrum.|Es gibt keinen Unterschied, beides sind Terminal-Server.|VDI SBC Architektur Vergleich Terminalserver
Bachelor Professional IT|VDI-Komponenten|Welche zentrale Funktion erfüllt der <b>Connection Broker</b> in einer VDI-Umgebung und warum wird er als "Schwäche" (Kostenfaktor) gelistet?|Verkehrspolizist|Management-Layer|Der <b>Connection Broker</b> ist die Schaltzentrale.<br>- Funktion: Er authentifiziert den User und <b>weist ihm eine freie VM</b> aus dem Pool zu (oder verbindet ihn mit "seinem" festen Desktop).<br>- Schwäche: Es ist eine komplexe, <b>teure Zusatzsoftware</b> (Lizenzkosten), die hochverfügbar ausgelegt sein muss.|Ohne Broker weiß der Thin Client nicht, mit welcher der 500 VMs er sich verbinden soll. Fällt der Broker aus, kann sich niemand anmelden (SPoF).|Citrix StoreFront oder VMware Horizon Connection Server.|Broker = Vermittler|Er vermittelt den User zur richtigen VM (Zuweisung/Authentifizierung).|Er dient als Virenscanner für die virtuellen Desktops.|Er ist nur ein physisches Kabel.|Er speichert die Backups der User-Daten.|VDI Connection-Broker Infrastruktur Management
Bachelor Professional IT|Einsatzszenarien VDI|Eine Ingenieurs-Abteilung benötigt CAD-Software mit hoher 3D-Leistung. Die IT-Leitung entscheidet sich gegen Terminal-Server (SBC) und für <b>VDI</b>. Welches technische Argument ist hier ausschlaggebend?|Performance-Hunger|GPU-Support|Für CAD ist <b>VDI</b> zwingend, wegen:<br>1. <b>Dedizierter Performance</b>: Man kann einer VM eine echte Grafikkarte (vGPU/Passthrough) fest zuweisen.<br>2. <b>Kompatibilität</b>: CAD-Software ist oft nur für Workstation-OS (Win 10/11) zertifiziert, nicht für Server-OS (SBC).|SBC (Terminal Server) teilt CPU/GPU unter allen Nutzern auf. Wenn einer rendert, steht bei den anderen das Bild. VDI garantiert die Leistung.|AutoCAD oder Adobe Premiere benötigen VDI für flüssiges Arbeiten.|CAD braucht Power = VDI|Dedizierte Ressourcen (GPU-Passthrough) und volle Software-Kompatibilität.|VDI ist billiger in der Anschaffung.|SBC unterstützt keine Maus-Eingaben.|VDI verbraucht weniger Strom im Rechenzentrum.|Szenario CAD VDI GPU Performance
Bachelor Professional IT|Netzwerk-Virtualisierung|Was ist der entscheidende administrative Vorteil der <b>Netzwerk-Virtualisierung</b> (z. B. VLANs) gegenüber einer rein physischen Segmentierung?|Logik vs. Physik|Flexibilität|Der Vorteil ist die <b>Entkopplung von der Physik</b>.<br>- Man kann Ressourcen (z. B. VLANs) logisch gruppieren, optimieren und sichern, <b>ohne die physische Verkabelung ändern zu müssen</b>.<br>- Ein Umzug einer Abteilung erfordert kein Umstecken im Verteilerschrank, sondern nur eine Software-Konfiguration am Port.|Früher musste man für ein getrenntes "Buchhaltungs-Netz" eigene Switches kaufen und Kabel ziehen. Heute konfiguriert man VLAN 10 auf dem vorhandenen Switch.|Abteilung zieht um -> Nur VLAN-ID am Switch-Port ändern.|VLAN = Logisches Kabel|Optimierung von Sicherheit/Struktur ohne Änderung der physischen Verkabelung.|Die Datenübertragungsrate verdoppelt sich automatisch.|Man benötigt keine Switches mehr, nur noch Hubs.|Es erhöht den Stromverbrauch der Router.|VLAN Netzwerk Virtualisierung Administration
Bachelor Professional IT|Anwendungs-Virtualisierung|Wie unterscheiden sich <b>Lokale Anwendungs-Virtualisierung</b> und <b>Serverbasierte Anwendungs-Virtualisierung</b> hinsichtlich des <b>Ortes der Ausführung</b> (Rechenlast)?|Wo raucht der Kopf?|Client vs. Server|Der Unterschied liegt in der <b>CPU-Last</b>:<br>1. <b>Lokal</b>: Die Anwendung läuft auf dem <b>Endpunkt (Client)</b> in einer isolierten Blase (Sandbox). Der Client braucht Rechenleistung.<br>2. <b>Serverbasiert</b>: Die Anwendung läuft komplett auf dem <b>Server</b>. Nur das UI (Bild) wird übertragen. Der Client kann "dumm" sein.|Wichtig für die Beschaffung: Bei lokaler App-Virti (z. B. MS App-V) brauchen Sie starke PCs. Bei serverbasierter (z. B. Citrix XenApp) reichen Thin Clients, aber Sie brauchen starke Server.|Lokal: Sandbox auf dem PC. Server: Fernsteuerung.|Lokal = Client-Last, Server = Server-Last|Lokal = Client-CPU (Isoliert); Serverbasiert = Server-CPU (nur Bildübertragung).|Beide laufen immer auf dem Server.|Lokal läuft im Browser, Serverbasiert auf dem Handy.|Lokal benötigt keine CPU, Serverbasiert benötigt GPU.|App-V SBC Architektur Sizing
Bachelor Professional IT|Software-Verteilung|Ein Unternehmen möchte eine riesige Software-Suite bereitstellen. Um Speicherplatz auf den Laptops zu sparen, sollen <b>Programmkomponenten nur bei tatsächlichem Bedarf</b> vom Server zum Client übertragen werden. Welche Technologie beschreibt dies?|Just-in-Time Delivery|Häppchen-Weise|<b>Anwendungs-Streaming</b>.<br>- Prinzip: Der Server sendet <b>Programmkomponenten (Code-Blöcke)</b> erst dann, wenn der User sie anklickt/benötigt.<br>- Vorteil: Die App startet sofort (nur der Core wird geladen), ohne dass Gigabytes installiert werden müssen.|Vergleichbar mit Netflix: Man schaut den Film (nutzt die App), während der Rest noch lädt. Das spart massiv Speicherplatz auf dem Client und Bandbreite beim Rollout.|Starten von Word dauert Sekunden, obwohl die Rechtschreibprüfung noch gar nicht heruntergeladen ist.|Streaming = Laden bei Bedarf|Anwendungs-Streaming.|VPN (Virtual Private Network).|Lokale Installation per MSI-Paket.|RAID 5 Spiegelung.|Streaming Software Deployment App-V
Bachelor Professional IT|Container Technologie|Was beinhaltet eine <b>Container-Einheit</b> technisch gesehen und welches fundamentale Problem der Softwareverteilung wird durch diese Kapselung gelöst?|Portabilität|Alles dabei|Ein Container verpackt den <b>Anwendungscode inklusive aller Bibliotheken und Abhängigkeiten</b> (Binaries, Configs).<br>- Lösung: Er eliminiert das "Works on my machine"-Problem. Da alles Nötige im Container ist, läuft er überall gleich (Dev, Test, Prod), unabhängig vom darunterliegenden System.|Im Gegensatz zur VM fehlt hier das eigene Betriebssystem. Der Container ist nur ein "Prozess mit Gepäck". Das macht ihn extrem portabel.|Docker-Image enthält Java-App + JRE + Configs.|Container = App + Libs (All-in-One)|Anwendungscode + Bibliotheken/Abhängigkeiten; löst Kompatibilitätsprobleme.|Nur den reinen Quellcode ohne Compiler.|Ein komplettes Gast-Betriebssystem inklusive Kernel.|Nur die Datenbank-Treiber.|Container Definition Docker Deployment
Bachelor Professional IT|Container-Architektur|Auf welcher technischen Basis realisieren Container ihre Isolation, ohne einen Hypervisor zu benötigen?|Shared Kernel|Namespaces & Cgroups|Sie nutzen die <b>Betriebssystem-Virtualisierung</b>.<br>- Spezifische <b>Kernel-Funktionen</b> (wie <b>Namespaces</b> für die Sichtbarkeit und Cgroups für Ressourcen) isolieren die Prozesse voneinander.<br>- Alle Container teilen sich den Kernel des Host-Betriebssystems.|Das ist der entscheidende Unterschied zur VM: Kein Hypervisor, kein Overhead durch Gast-OS-Starts. Ein Container ist für den Kernel nur ein isolierter Prozess.|Linux Namespaces sorgen dafür, dass Prozess A den Prozess B nicht "sieht".|Container = Shared Kernel|Durch Betriebssystem-Virtualisierung (Kernel-Funktionen wie Namespaces).|Durch physische Partitionierung der Festplatte.|Durch Emulation einer kompletten CPU.|Durch Nutzung eines Typ-2 Hypervisors.|Container Virtualisierung Kernel Namespaces
Bachelor Professional IT|Cloud-Native Strategie|Ein Unternehmen entwickelt eine Microservices-Architektur mit hunderten kleinen Services. Warum sind <b>Container</b> hierfür laut Definition besser geeignet als klassische <b>VMs</b>?|Dichte & Speed|Leichtgewicht|Container sind <b>ressourceneffizienter und mobiler</b>.<br>- Grund: Da sie kein eigenes OS mitschleppen (kein RAM/CPU für Leerlauf des Gast-OS), können auf einem Server hunderte Container laufen, wo früher nur dutzende VMs passten.<br>- Dies ist der Standard für <b>cloudnative Anwendungen</b> (Skalierbarkeit).|Startzeit VM: Minuten. Startzeit Container: Millisekunden. Bei Microservices, die schnell skalieren müssen (z. B. Black Friday im Shop), ist das entscheidend.|Kubernetes orchestriert tausende Container effizienter als eine VM-Farm.|Container = Effizienz-Champion|Wegen höherer Ressourceneffizienz (kein OS-Overhead) und Mobilität.|Weil Container eine grafische Oberfläche für den User bieten.|Weil VMs keine Netzwerkverbindung erlauben.|Weil Container teurer sind und mehr Umsatz generieren.|Szenario Microservices Cloud Container VM-Vergleich
Bachelor Professional IT|Datensicherung (Backup)|Was ist die exakte Definition einer <b>Datensicherung (Backup)</b> und welches primäre zeitliche Ziel verfolgt sie im IT-Betrieb?|Lebensversicherung|Kopie & Restore|Datensicherung ist das <b>Kopieren von Daten</b> mit dem Ziel, diese im Falle eines Datenverlusts <b>wiederherstellen</b> zu können.<br>- Schutz vor: Technischem Versagen, Löschen oder Manipulation.<br>- Ziel: Die <b>kurzfristige Wiederaufnahme</b> des IT-Betriebs (Business Continuity).|Abgrenzung: Ein Backup ist eine Kopie (Redundanz). Ein Archiv ist oft eine Verschiebung (Original weg, Kopie im Archiv). RAID schützt vor Hardware-Ausfall, aber nicht vor Löschung (User-Fehler).|Täglich um 22 Uhr wird der Dateiserver auf ein Tape kopiert.|Backup = Kopie für Notfall|Kopieren von Daten zur Wiederherstellung; Ziel: Kurzfristige Wiederaufnahme des Betriebs.|Verschieben von Daten zur Entlastung des Speichers (Langzeit).|Spiegelung von Festplatten für den laufenden Betrieb (RAID).|Löschen von nicht mehr benötigten Dateien.|Backup Definition Restore Verfügbarkeit
Bachelor Professional IT|Backup-Strategien|Wie unterscheiden sich die <b>Sicherung einzelner Dateien</b> und das <b>Disaster Recovery</b> hinsichtlich ihres Wiederherstellungs-Umfangs?|Granularität|Teil vs. Ganzes|Der Unterschied liegt im Scope:<br>1. <b>Einzelsicherung</b>: Sichert selektiv Nutzerdaten (z. B. Excel-Tabellen). Wiederherstellung einzelner Elemente möglich.<br>2. <b>Disaster Recovery</b>: Zielt auf die <b>Wiederherstellung des Gesamtzustands</b>. Dies umfasst Betriebssystem, Konfigurationen, Anwendungen und Daten, um nach einem Totalausfall (z. B. Brand) den Server komplett neu aufzubauen.|Disaster Recovery ist komplexer (Image-Backups, Bare-Metal-Restore), aber notwendig, wenn die Hardware getauscht wurde und das OS neu muss. Einzelsicherung hilft, wenn "Frau Müller" versehentlich einen Ordner löscht.|Bare-Metal-Restore des Exchange-Servers (DR) vs. Rücksichern einer gelöschten Mail (Single Item).|DR = Alles zurück auf Start|Einzeldateien = Selektiv; Disaster Recovery = Gesamtzustand (OS + Apps + Daten).|Beide sichern nur Word-Dokumente.|Einzeldateien für Server, Disaster Recovery für Laptops.|Disaster Recovery löscht Daten, Dateisicherung speichert sie.|Backup Disaster-Recovery Strategie Restore
Bachelor Professional IT|Schutzziele & Grenzen|Ein Mitarbeiter löscht versehentlich einen kritischen Projektordner, und zeitgleich verschlüsselt ein Virus (Ransomware) Teile der Festplatte. Warum hilft hier ein <b>RAID-System</b> (Spiegelung) nicht, sondern nur ein <b>Backup</b>?|Logischer Fehler vs. Physik|RAID ist kein Backup|Ein RAID-System spiegelt Daten in Echtzeit zur Erhöhung der Verfügbarkeit bei Hardware-Ausfall.<br>- Problem: Es spiegelt auch <b>logische Fehler</b> (Löschung, Viren) sofort auf die zweite Platte.<br>- Nur ein <b>Backup</b> (Offline-Kopie zu einem früheren Zeitpunkt) ermöglicht den Sprung zurück vor den Fehler.|Dieser Merksatz ist prüfungsentscheidend: "RAID erhöht die Verfügbarkeit, Backup sichert die Datenintegrität/Wiederherstellung."|Virus verschlüsselt Platte 1 -> RAID verschlüsselt sofort Platte 2. Daten weg. Backup vom Vortag -> Daten da.|Backup > RAID bei Logik-Fehlern|Weil RAID den Fehler (Löschung/Verschlüsselung) sofort auf die Spiegelplatte schreibt.|Weil RAID nur nachts läuft.|Weil RAID nur vor Feuer schützt.|Weil RAID Daten komprimiert und unlesbar macht.|Szenario RAID Backup Ransomware Sicherheit
Bachelor Professional IT|Datensicherung|Wie unterscheiden sich die Konzepte der Vollsicherung (Full Backup) und der Image-Datensicherung in Bezug auf Technik und Wiederherstellung?|Logische vs. Physikalische Sicherung|Dateisystem vs. Sektorkopie|Die <b>Vollsicherung</b> kopiert alle ausgewählten <b>logischen Dateien</b> eines Systems. Die <b>Image-Sicherung</b> erstellt ein exaktes Abbild der <b>physikalischen Sektoren</b>.<br>- Vollsicherung: Einfaches Handling einzelner Dateien.<br>- Image: Extrem schnelle Wiederherstellung ganzer Systeme (Bare Metal).|Image-Sicherungen sind essenziell für das Disaster Recovery, da sie Boot-Sektoren und Systemkonfigurationen mitsichern. Vollsicherungen sind flexibler bei der granularen Wiederherstellung (Single Item Restore) auf unterschiedlicher Hardware.|Wiederherstellung eines kompletten Webservers nach Ransomware-Befall mittels Image vs. Rücksicherung eines gelöschten PDF-Dokuments aus der Vollsicherung.|Voll = Datei-Fokus, Image = Sektor-Spiegel|Vollsicherung basiert auf logischen Dateien; Image auf physikalischen Sektoren des Datenträgers.|Ein Image sichert nur geänderte Dateien seit der letzten Vollsicherung.|Die Vollsicherung arbeitet sektororientiert, das Image dateiorientiert.|Beide Methoden benötigen für die Wiederherstellung zwingend ein inkrementelles Backup.|Backup Datensicherung Recovery BSI-Grundschutz IT-Betrieb
Bachelor Professional IT|Datensicherung|Erläutern Sie den technischen Unterschied zwischen einem differentiellen und einem inkrementellen Backup-Verfahren hinsichtlich der Referenzpunkte?|Referenzpunkt der Sicherung|Zuwachs vs. Kumulation|Das <b>differentielle Backup</b> sichert alle Änderungen seit dem <b>letzten Vollbackup</b> (wachsendes Delta). Das <b>inkrementelle Backup</b> sichert nur die Änderungen seit der <b>letzten inkrementellen Sicherung</b> (kleine Fragmente).|Differentiell: Höherer Speicherbedarf, schnellere Rücksicherung (Vollbackup + 1 Diff-Band). Inkrementell: Minimaler Speicherbedarf, langsame/riskante Rücksicherung (Vollbackup + alle Inkremente in korrekter Kette).|Wahl eines inkrementellen Backups bei schmaler Bandbreite zur Außenstelle vs. differentielles Backup für kritische Datenbanken mit Fokus auf RTO.|Diff = Zurück zum Start (Voll), Inkr = Schritt für Schritt (Kette)|Differentiell referenziert das letzte Vollbackup; Inkrementell die jeweils letzte (Teil-)Sicherung.|Inkrementelle Backups sichern immer alle Änderungen seit der letzten Vollsicherung.|Differentiell bezieht sich auf das letzte inkrementelle Band.|Beide Verfahren setzen das Archiv-Bit niemals zurück.|Backup Inkrementell Differentiell Speicherstrategie RTO RPO
Bachelor Professional IT|Datensicherung|Ein Unternehmen fordert eine Reduzierung der Wiederherstellungszeit (RTO) nach einem Systemausfall am Freitag. Bisher wurde täglich inkrementell gesichert. Welche Änderung der Strategie ist ratsam?|Recovery Time Objective (RTO) optimieren|Anzahl der Backup-Medien reduzieren|Ein Wechsel auf <b>differentielle Sicherung</b> verkürzt die RTO, da im Ernstfall nur das <b>letzte Vollbackup</b> und das <b>letzte differentielle Medium</b> eingespielt werden müssen.<br>- Vorteil: Weniger Handling-Fehler.<br>- Nachteil: Längeres Zeitfenster für die tägliche Sicherung am Donnerstag/Freitag.|Die RTO (Recovery Time Objective) ist bei inkrementellen Ketten hoch, da bei einem Ausfall am Freitag das Vollbackup (Mo) + Inkr (Di, Mi, Do) benötigt werden. Jedes Medium steigert das Ausfallrisiko. Differentiell benötigt immer nur zwei Schritte.|Ein Admin muss 5 Bänder suchen (Inkrementell) vs. nur 2 Bänder (Differentiell) für den Restore am Freitagabend.|Inkrementell = Viele Glieder (Kette), Differentiell = Zwei Teile (Paar)|Umstellung auf differentielle Sicherung, um die Anzahl der einzuspielenden Medien zu minimieren.|Umstellung auf tägliche Image-Sicherungen ohne Vollsicherung.|Wechsel auf ausschließlich inkrementelle Sicherungen ohne Vollbackup.|Erhöhung der Bandlaufgeschwindigkeit bei gleichbleibender Strategie.|IT-Management RTO Backup-Strategie Disaster-Recovery Business-Continuity
Bachelor Professional IT|Datensicherungsmethoden|Was ist das definierende technische Merkmal von <b>Continuous Data Protection (CDP)</b> im Vergleich zu einem klassischen, täglichen inkrementellen Backup?|Zeitstrahl vs. Zeitpunkt|Journaling|CDP speichert <b>kontinuierlich jede einzelne Datenveränderung</b> (jeden Schreibvorgang) in einem Journal/Log.<br>- Unterschied: Ein klassisches Backup erzeugt statische Punkte (z. B. jede Nacht). CDP erzeugt einen lückenlosen Film der Datenhistorie.<br>- Ergebnis: Man kann zu <b>jedem beliebigen Zeitpunkt</b> in der Vergangenheit zurückkehren.|CDP ist wie die "Rückgängig"-Taste (STRG+Z) in Word, aber für den gesamten Server. Klassisches Backup ist wie "Speichern unter" einmal am Tag.|CDP = Videorekorder, Backup = Fotoalbum|Kontinuierliche Speicherung aller Änderungen; Rückkehr zu *jedem* Zeitpunkt.|Es komprimiert Daten stärker, um Speicher zu sparen.|Es sichert Daten nur, wenn der Server heruntergefahren ist.|Es erstellt einmal pro Stunde einen Wiederherstellungspunkt.|CDP Backup Definition RPO Recovery
Bachelor Professional IT|Disaster Recovery Kennzahlen|Welchen konkreten Einfluss hat der Einsatz von CDP auf die Kennzahl <b>RPO (Recovery Point Objective)</b> – also den maximal tolerierbaren Datenverlust?|Datenverlust-Minimierung|Near-Zero Data Loss|Durch CDP geht der <b>RPO gegen Null</b>.<br>- Begründung: Da jede Transaktion sofort protokolliert wird, gehen im Ernstfall nur die Daten der letzten Millisekunden (die noch im Cache waren) verloren, nicht die der letzten Stunden.<br>- Einsatzgebiet: Hochkritische Datenbanken (Banken, Börse), wo ein Datenverlust von einem Tag inakzeptabel wäre.|Vergleich: Bei einem täglichen Backup (Nachts 2 Uhr) beträgt der RPO im schlimmsten Fall 24 Stunden (Crash um 1:59 Uhr). Bei CDP sind es Sekunden.|RPO = 0 heißt: Nichts geht verloren.|Der RPO geht gegen Null (nahezu kein Datenverlust).|Der RPO steigt auf 24 Stunden.|Der RPO ist irrelevant, da CDP nur die RTO (Zeit) optimiert.|Der RPO bleibt unverändert hoch.|RPO CDP Datenverlust SLA
Bachelor Professional IT|Datenbank-Rettung|Um 14:15 Uhr führt ein Admin versehentlich ein SQL-Skript aus, das wichtige Kundendaten löscht. Das letzte Snapshot-Backup lief um 12:00 Uhr. Welchen Vorteil bietet <b>CDP</b> in dieser Situation gegenüber dem Snapshot?|Präzisions-Landung|Rückspulen|CDP ermöglicht ein <b>Point-in-Time Recovery</b> auf die Sekunde genau.<br>- Lösung: Man spult das System auf den Zustand um <b>14:14:59 Uhr</b> zurück.<br>- Vorteil: Der Datenverlust ist minimal (nur die eine Sekunde), während beim Snapshot alle Änderungen zwischen 12:00 und 14:15 Uhr (2h 15min) verloren wären.|Snapshots haben Lücken (das Delta zwischen zwei Aufnahmen). CDP schließt diese Lücken. Das ist bei Transaktionssystemen (Onlineshops) bares Geld wert.|Wie bei einem Video: Man spult genau dorthin zurück, bevor der Unfall passierte.|CDP = Zeitmaschine|Point-in-Time Recovery auf die Sekunde vor dem Fehler (14:14:59).|Man muss das Backup von 12:00 Uhr einspielen und verliert 2 Stunden Arbeit.|CDP verhindert das Löschen durch eine Firewall.|CDP kann die gelöschten Daten automatisch neu erfinden.|Szenario CDP Restore Datenbank Fehler
Bachelor Professional IT|Datensicherung|Erläutern Sie die Hierarchie und die typischen Sicherungsintervalle des Generationen-Rotationsprinzips (Großvater-Vater-Sohn).|Zeitliche Staffelung|Täglich vs. Wöchentlich vs. Monatlich|Das <b>Großvater-Vater-Sohn-Prinzip (GVS)</b> strukturiert die Datensicherung in drei Ebenen:<br>- <b>Sohn:</b> Tägliche Sicherung (oft inkrementell/differentiell).<br>- <b>Vater:</b> Wöchentliche Sicherung (Vollsicherung).<br>- <b>Großvater:</b> Monatliche Sicherung (Vollsicherung/Archivierung).|Diese Rotation ist der Standard für Langzeit-Datenverfügbarkeit. Während der 'Sohn' für operative Fehler (gelöschte Datei gestern) genutzt wird, dient der 'Großvater' dem Schutz vor schleichender Datenkorruption oder Ransomware, die erst nach Wochen bemerkt wird.|Ein Unternehmen bewahrt 4 Bänder für die Woche (Sohn), 4 Bänder für den Monat (Vater) und 12 Bänder für das Jahr (Großvater) auf.|Sohn ist jung (Tag), Vater reifer (Woche), Großvater alt (Monat).|Sohn = Täglich, Vater = Wöchentlich (Voll), Großvater = Monatlich (Voll).|Sohn = Monatlich, Vater = Wöchentlich, Großvater = Täglich.|Alle drei Generationen führen täglich ein Vollbackup durch.|Das Prinzip dient primär der Einsparung von Hardware-Anschaffungskosten.|GVS-Prinzip Datensicherung Rotation Archivierung Backup-Management
Bachelor Professional IT|Datensicherung|Welchen spezifischen strategischen Vorteil bietet die Vorhaltung der "Großvater"-Generation gegenüber einer rein täglichen Sicherungsschleife?|Langzeitschutz|Schleichende Fehler erkennen|Die Vorhaltung älterer Stände (Großvater) ermöglicht den Zugriff auf <b>konsistente Daten</b>, falls neuere Backups (Sohn/Vater) bereits <b>korrupte Daten</b> oder <b>Schadsoftware</b> enthalten, die unbemerkt mitgesichert wurden.|In der IT-Sicherheit ist das 'Backup-Poisoning' eine Gefahr. Angreifer warten oft Wochen, bevor sie Daten verschlüsseln. Ohne die Großvater-Generation wären alle verfügbaren Backups bereits infiziert.|Ein Buchhaltungsfehler wird erst nach 3 Wochen bemerkt. Die täglichen Sicherungen enthalten bereits den Fehler; nur das Monats-Backup (Großvater) ist noch fehlerfrei.|Alte Besen kehren gut (Großvater rettet bei alten Fehlern).|Schutz vor unbemerktem Datenverlust oder Korruption über längere Zeiträume.|Die Großvater-Generation beschleunigt die tägliche Wiederherstellungszeit (RTO).|Sie ersetzt die Notwendigkeit einer Firewall und Antivirus-Software.|Sie dient lediglich der Einhaltung der DSGVO-Löschfristen.|Sicherheitsstrategie Datenintegrität GVS-Prinzip Revision
Bachelor Professional IT|Datensicherung|Ein IT-Leiter möchte das GVS-Prinzip einführen. Wie viele physische Medien werden mindestens für ein Jahr benötigt, wenn die Söhne (Mo-Do) wöchentlich überschrieben werden?|Kapazitätsplanung|Medien-Rotation berechnen|Für eine Standard-GVS-Rotation mit Erhalt der Väter/Großväter kalkuliert man:<br>- <b>4 Söhne</b> (Rotation Mo-Do),<br>- <b>4 Väter</b> (Wochen-Backups des aktuellen Monats),<br>- <b>12 Großväter</b> (Monats-Backups des Jahres).<br>Gesamt: <b>20 Medien</b>.|Diese Kalkulation ist die Basis für das Budgeting der Backup-Hardware. Durch das Überschreiben der Söhne wird Speicherplatz gespart, während die Väter/Großväter die gesetzliche Revisionssicherheit und Desasterschutz gewährleisten.|Planung des Einkaufs von LTO-Bändern für ein neues Tape-Library-System in einem mittelständischen Betrieb.|4-4-12 Regel (Sohn-Vater-Opa)|20 Medien (4 Söhne + 4 Väter + 12 Großväter).|365 Medien (eines für jeden Tag des Jahres).|7 Medien (eines für jeden Wochentag).|12 Medien (nur für die Monatsenden).|IT-Controlling Backup-Planung GVS Investitionsplanung
Bachelor Professional IT|Datensicherungskonzeption (BSI)|Welche elementaren Verfahrensweisen müssen in der Phase <b>"Planung und Konzeption"</b> zwingend festgelegt werden, <i>bevor</i> Hard- oder Software beschafft wird?|Strategie vor Technik|W-Fragen des Backups|In der Planungsphase müssen die <b>Verfahrensweisen</b> definiert werden:<br>1. <b>Häufigkeit</b>: Wann wird gesichert?<br>2. <b>Medien</b>: Worauf wird gesichert?<br>3. <b>Verantwortlichkeiten</b>: Wer wechselt die Bänder/überwacht die Jobs?<br>4. <b>Aufbewahrungsort</b>: Wo lagern die Kopien (extern/feuerfest)?|Erst wenn diese Anforderungen (und das Minimaldatensicherungskonzept) stehen, kann man in Phase 2 die passende Hardware kaufen. Wer Hardware ohne Konzept kauft, erfüllt meist die RTO/RPO-Ziele nicht.|Definition, dass täglich gesichert wird und Bänder extern lagern (Planung), bevor das LTO-Laufwerk bestellt wird (Beschaffung).|Planung = Wer, Wie, Wo, Wann|Festlegung von Häufigkeit, Medien, Verantwortlichkeiten und Aufbewahrungsort.|Installation der Agenten auf den Clients.|Kauf der teuersten Hardware, um sicher zu sein.|Durchführung eines Restore-Tests.|BSI Konzept Planung Strategie Backup
Bachelor Professional IT|Backup-Betrieb|Neben der regelmäßigen Erstellung der Kopien: Welche oft vergessene Maßnahme schreibt das BSI in der Phase <b>"Betrieb"</b> vor, um physische Medienalterung zu erkennen?|Qualitätssicherung|Vertrauen ist gut, Kontrolle ist besser|Die <b>sporadische Lesbarkeitsprüfung</b>.<br>- Ziel: Sicherstellen, dass die physischen Datenträger (Tapes, HDDs) noch intakt sind und die Daten fehlerfrei zurückgelesen werden können.<br>- Kontext: Medien altern (Bit-Rot, Magnetisierungsschwund). Ein Backup, das zwar "Erfolgreich" meldet, aber auf einem defekten Band liegt, ist wertlos.|Dies gehört zur Routine im Betrieb, genau wie die sichere Lagerung und Dokumentation. Ein Restore-Test (Notfallvorsorge) prüft den Prozess, die Lesbarkeitsprüfung (Betrieb) prüft das Medium.|Ein Admin zieht zufällig ein Band aus dem Vorjahr und prüft, ob die Datei "Bilanz.xlsx" noch lesbar ist.|Lesbarkeit = Medium-Check|Sporadische Lesbarkeitsprüfungen der Datenträger.|Tägliche Neuformatierung der Bänder.|Jährlicher Neukauf aller Festplatten.|Verschlüsselung der Daten.|BSI Betrieb Lesbarkeit Wartung
Bachelor Professional IT|Notfallvorsorge|Ein Unternehmen sichert täglich und lagert Bänder aus. Nach einem Server-Crash stellt sich heraus, dass die Wiederherstellung 3 Tage dauert, was zum Bankrott führt, da niemand den Ablauf vorher geübt hatte. Welche Phase des BSI-Konzepts wurde hier vernachlässigt?|Probe für den Ernstfall|Übung macht den Meister|Die <b>Notfallvorsorge</b>.<br>- Inhalt: <b>Funktionstests</b> und die Validierung des <b>Restore-Plans</b>.<br>- Ziel: Sicherstellen, dass die Daten nicht nur existieren, sondern auch in der geforderten Zeit (RTO) wiederherstellbar sind.|Ein Backup-Konzept ohne Restore-Test ist wertlos ("Schrödingers Backup"). Nur wer den Ernstfall probt, kennt die wahren Wiederherstellungszeiten.|Ein "Fire Drill" für die IT: Einmal im Jahr wird ein Server absichtlich gelöscht und vom Azubi wiederhergestellt.|Notfallvorsorge = Restore-Test|Notfallvorsorge (Funktionstests und Prüfung des Restore-Plans).|Betrieb (Die Backups waren ja da).|Beschaffung (Die Hardware war vorhanden).|Umsetzung (Mitarbeiter waren verpflichtet).|Szenario Restore BSI Notfallvorsorge
Bachelor Professional IT|Archivierung|Definieren Sie "Archivierung" im IT-Kontext und grenzen Sie diese primär vom Begriff "Backup" ab.|Zweckbestimmung|Langzeit vs. Kurzzeit|Die <b>Archivierung</b> ist die <b>dauerhafte, unveränderbare</b> Speicherung von Daten, die nicht mehr aktiv genutzt werden (Aufbewahrungspflicht). Das <b>Backup</b> dient der <b>kurzfristigen Sicherung</b> zur Wiederherstellung nach Datenverlust.|Während ein Backup regelmäßig überschrieben wird (Rotation), muss ein Archiv über Jahre hinweg (z. B. 10 Jahre gemäß GoBD) lesbar und manipulationssicher bleiben. Backups sind operativ, Archive sind administrativ/rechtlich.|Ein abgeschlossenes Projekt wird vom Fileserver ins Archiv verschoben (Platzersparnis), während die Datenbank jede Nacht ein Backup erhält (Sicherheit).|Archiv = Gesetz (Statisch), Backup = Rettung (Dynamisch)|Archivierung ist die langfristige, unveränderbare Aufbewahrung; Backup die kurzfristige Datensicherung.|Archivierung ist eine Kopie zur schnellen Wiederherstellung bei Defekten.|Backup dient der langfristigen, unveränderbaren Aufbewahrung.|Archivierung und Backup beschreiben technisch identische Vorgänge.|Datenmanagement Compliance GoBD Backup-Unterschied
Bachelor Professional IT|Archivierung|Welche technische Eigenschaft ist für ein elektronisches Archiv (z. B. in einem DMS) zwingend erforderlich, um als "revisionssicher" zu gelten?|Compliance-Anforderungen|Schutz vor Veränderung|Ein Archiv muss <b>revisionssicher</b> sein, d. h. Daten müssen <b>unveränderbar</b> und <b>verlustfrei</b> gespeichert werden. Dies wird oft durch <b>WORM-Medien</b> (Write Once Read Many) oder kryptografische Signaturen/Hashes sichergestellt.|Revisionssicherheit umfasst nach GoBD: Ordnungsmäßigkeit, Vollständigkeit, Sicherheit des Gesamtverfahrens, Verfügbarkeit und Unveränderbarkeit. Ein DMS automatisiert diese Prozesse durch Versionierung und Audit-Logs.|Revisionssichere Archivierung von Eingangsrechnungen, die nach dem Scannen nicht mehr ohne Protokollierung geändert werden können.|Revisionssicher = Festgeschrieben (Nicht manipulierbar)|Die Unveränderbarkeit (Manipulationsschutz) über den Aufbewahrungszeitraum.|Die Daten müssen auf mobilen Festplatten gelagert werden.|Eine tägliche Löschung alter Protokolle muss möglich sein.|Der Zugriff muss für jeden Mitarbeiter ohne Passwort möglich sein.|DMS Revisionssicherheit GoBD Compliance WORM
Bachelor Professional IT|Archivierung|Ein Unternehmen leidet unter vollen, teuren SSD-Speichern auf dem Fileserver. Wie kann eine Archivierungslösung (HSM) hier strategisch helfen?|Speicheroptimierung|Tiering-Konzept|Ein <b>HSM-System</b> verschiebt <b>inaktive Daten</b> (nach definierten Regeln) automatisch vom teuren Primärspeicher (SSD) auf <b>kostengünstige Archivspeicher</b> (HDD/Cloud/Tape), hält sie aber logisch für den Nutzer verfügbar.|Dies senkt die TCO (Total Cost of Ownership), da die Kapazität des schnellen Speichers für produktive Prozesse frei bleibt. Zudem verkürzen sich die Backup-Zeiten für den Primärspeicher, da weniger Daten gesichert werden müssen.|Auslagerung von 5 Jahre alten Projekt-PDFs auf ein langsames NAS, während aktuelle Dokumente auf dem NVMe-Flash verbleiben.|Heißes (aktiv) auf SSD, Kaltes (inaktiv) ins Archiv.|Durch automatische Auslagerung inaktiver Daten auf kostengünstigere Sekundärspeicher.|Durch Komprimierung aller aktiven Daten auf dem Primärspeicher.|Durch den vollständigen Verzicht auf Backups der SSDs.|Indem alle Daten auf langsamere Bänder gelöscht werden.|HSM Storage-Tiering TCO Infrastruktur Archivierung
Bachelor Professional IT|Monitoring Grundlagen|Was ist die exakte Definition von <b>Monitoring</b> und welches primäre operative Ziel wird durch die Identifikation von Indikatoren verfolgt?|Blindflug vermeiden|Prävention|Monitoring ist die <b>Überwachung von IT-Komponenten</b> anhand definierter <b>Indikatoren und Parameter</b> (z. B. CPU-Last, Ping).<br>- Primärziel: Sicherstellung eines reibungslosen Betriebs durch Identifikation und Lokalisierung von Problemen, <b>bevor Schäden entstehen</b> (Proaktivität).|Ohne Monitoring merkt die IT erst, dass der Mailserver steht, wenn der Chef anruft. Mit Monitoring meldet das System proaktiv: "Queue läuft voll".|Dashboard rot = Handeln bevor User anruft.|Überwachung von Komponenten anhand von Parametern; Ziel: Problemlösung bevor Schäden entstehen.|Überwachung der Mitarbeiter-Performance am PC.|Nachträgliche Analyse von Logfiles nach einem Crash.|Automatische Installation von Updates.|Monitoring Definition Proaktiv IT-Betrieb
Bachelor Professional IT|Monitoring Kontext|Für welche vier IT-Management-Disziplinen liefert das Monitoring die essenziellen Daten-Grundlagen?|Datenlieferant|C.S.A.S.|Monitoring ist essenziell für:<br>1. <b>Capacity-Management</b>: Wann ist die Festplatte voll? (Trendanalyse)<br>2. <b>Service-Level-Management</b>: Wurde die vereinbarte Uptime (99,9%) eingehalten? (Nachweis)<br>3. <b>Availability-Management</b>: Ist der Dienst jetzt verfügbar? (Status)<br>4. <b>IT-Security-Management</b>: Gibt es ungewöhnliche Login-Versuche? (Angriffserkennung)|Monitoring ist nicht nur "Technik", sondern liefert die KPIs (Key Performance Indicators) für das Management. Ohne Monitoring-Daten ist kein SLA-Report möglich.|SLA-Report ohne Monitoring ist Raten.|Capacity-, Service-Level-, Availability- und IT-Security-Management.|Einkauf, Vertrieb, Marketing und HR.|Nur für die IT-Forensik.|Software-Entwicklung, Design, Testing und Rollout.|Monitoring Management ITIL SLA Capacity
Bachelor Professional IT|Capacity-Monitoring|Ein Server stürzt ab, weil die Festplatte zu 100% vollgeschrieben ist. Welcher Mechanismus des Monitorings wurde hier entweder nicht konfiguriert oder ignoriert, der dies hätte verhindern können?|Warnlampe|Indikator & Parameter|Ein <b>Schwellenwert-Alarm (Threshold)</b>.<br>- Das Monitoring misst den Parameter "Disk Space".<br>- Ist ein Indikator definiert (z. B. "Warnung bei > 90%"), kann der Admin reagieren (Dateien löschen/erweitern), <b>bevor</b> die 100% erreicht sind und das OS stoppt.|Das ist der Unterschied zwischen "Monitoring" (Zuschauen) und "Alerting" (Alarmieren). Ein Monitoring ohne gut eingestellte Schwellenwerte ist nutzlos (Alert Fatigue vermeiden!).|Tankanzeige im Auto: Lampe geht an bei 50km Restreichweite, nicht erst wenn der Tank leer ist.|90% Warnung rettet 100% Crash|Ein Schwellenwert-Alarm (Threshold) bei z. B. 90% Füllstand.|Das automatische Löschen von User-Daten.|Ein RAID-System (Spiegelung).|Eine USV (Notstrom).|Szenario Threshold Alerting Kapazität
Bachelor Professional IT|IT-Betrieb|Wodurch unterscheiden sich Real-Time Monitoring und Historical Monitoring hinsichtlich ihrer primären Zielsetzung?|Operativ vs. Strategisch|Alarmierung vs. Trendanalyse|<b>Real-Time Monitoring</b> überwacht den aktuellen Zustand zur <b>sofortigen Alarmierung</b> bei Ausfällen (Reaktionszeit).<br><b>Historical Monitoring</b> aggregiert Daten über lange Zeiträume für <b>Trendanalysen</b>, Kapazitätsplanung und Budgetierung (Prognose).|Ohne Real-Time keine SLA-Einhaltung (Downtime). Ohne Historical keine Investitionsplanung (Wann ist die Disk voll?). Historical hilft zudem, 'schleichende' Performance-Probleme zu erkennen, die im Real-Time-Rauschen untergehen.|Die CPU ist jetzt bei 99% (Real-Time -> Alarm) vs. Die CPU-Last steigt seit 6 Monaten um 5% pro Monat (Historical -> Neuer Server nötig).|Real = Jetzt (Feuerwehr), Historisch = Plan (Architekt)|Real-Time = Sofortige Alarmierung (Betrieb); Historical = Langzeittrend (Planung).|Real-Time dient der Budgetplanung, Historical der Alarmierung.|Beide Verfahren nutzen ausschließlich Live-Daten zur Fehlerbehebung.|Real-Time speichert Daten für 10 Jahre, Historical löscht sofort.|Monitoring Kapazitätsplanung SLA ITIL-Betrieb
Bachelor Professional IT|IT-Sicherheit & Betrieb|Was charakterisiert das Aktive Monitoring und welches spezifische Betriebsrisiko ist damit verbunden?|Self-Healing|Symptombekämpfung|Beim <b>Aktiven Monitoring</b> führt das System bei erkannten Fehlern <b>automatisch Gegenmaßnahmen</b> durch (z. B. Neustart eines Dienstes).<br><b>Risiken:</b><br>1. <b>Ursachenverschleierung:</b> Das Symptom wird behoben, der Root-Cause bleibt bestehen.<br>2. <b>Sicherheit:</b> Der Monitoring-Agent benötigt privilegierte Schreibrechte (Angriffsvektor).|Aktives Monitoring ist verlockend für 'Self-Healing'-Systeme, widerspricht aber oft dem 'Least Privilege'-Prinzip. Wenn ein Dienst jede Nacht abstürzt und neu gestartet wird, merkt der Admin es nicht, bis der Fehler so gravierend ist, dass der Restart nicht mehr hilft.|Ein Webserver-Dienst hängt. Das Monitoring startet ihn neu. Der Speicherleck-Fehler im Code (Ursache) wird dadurch nicht gefunden.|Aktiv = Eingreifen (Arzt), Passiv = Melden (Beobachter)|Automatische Fehlerbehebung durch das System; Risiko der Ursachenverschleierung.|Es überwacht nur passive Komponenten wie Kabel.|Es alarmiert nur per SMS, greift aber nie ein.|Es ist die sicherste Methode, da keine Admin-Rechte benötigt werden.|Monitoring IT-Security Root-Cause-Analysis Automatisierung
Bachelor Professional IT|IT-Management|Nutzer beschweren sich über einen langsamen Webshop, obwohl alle Server-Metriken (CPU, RAM, Disk) im "grünen Bereich" sind. Welches Monitoring-Verfahren fehlt und warum?|User Experience (UX)|Ganzheitliche Sicht|Es fehlt ein <b>End-to-End-Monitoring</b> (bzw. Application Response Time Monitoring).<br>Grund: Komponenten-Monitoring sieht nur die Hardware/OS-Ebene. Performance-Probleme durch <b>Datenbank-Locks</b>, fehlerhaften Code oder <b>Latenzen im externen Routing</b> werden nur durch die Simulation einer <b>echten Transaktion</b> (User-Sicht) erkannt.|Der Unterschied zwischen 'Server is up' und 'Service is available'. End-to-End-Monitoring nutzt oft synthetische Transaktionen (Robots), die regelmäßig einen Warenkorb-Checkout durchführen und die Zeit messen.|Die Autobahn ist frei (Server OK), aber das Auto hat einen Platten (Applikationsfehler).|E2E = Ende gut, alles gut (Ganze Kette)|End-to-End-Monitoring (oder Application Response Time), da es die Nutzerperspektive misst.|Das Historical Monitoring, um alte Logs zu prüfen.|Das Netzwerk-Monitoring auf Layer 2 (MAC-Adressen).|Das passive Monitoring der Stromversorgung.|End-to-End Application-Monitoring UX SLA Troubleshooting
Bachelor Professional IT|Netzwerk-Monitoring|Worauf konzentriert sich das Netzwerk-Monitoring primär und welche zentralen Metriken werden dabei überwacht?|OSI-Layer 2-4|Transportqualität|Das <b>Netzwerk-Monitoring</b> fokussiert sich auf die <b>Übertragungsqualität</b> und Verfügbarkeit der Infrastrukturkomponenten (Router, Switches). Zentrale Metriken sind:<br>- <b>Bandbreite</b> (Auslastung in MBit/s).<br>- <b>Latenz</b> (Verzögerung).<br>- <b>Jitter</b> (Schwankung der Latenz).<br>- <b>Packet Loss</b> (Verlorene Pakete).|Abgrenzung zum Applikations-Monitoring: Hier geht es darum, *wie schnell* und *zuverlässig* das 'Rohr' ist, nicht was inhaltlich durchfließt (Payload). Tools nutzen oft SNMP (Simple Network Management Protocol).|Ein VoIP-Gespräch bricht ab. Das Netzwerk-Monitoring zeigt einen Jitter von >30ms an (Ursache), während der Server selbst keine Lastprobleme hat.|Netz = Rohr (Dicke, Länge, Löcher)|Überwachung des Datenflusses (Durchsatz), der Latenz und der Paketverluste.|Überwachung des Speicherplatzes auf den File-Servern.|Analyse der PHP-Code-Effizienz in Webanwendungen.|Kontrolle der Zutrittsprotokolle zum Serverraum.|SNMP Bandbreite Latenz Jitter QoS
Bachelor Professional IT|IoT / Industrie 4.0|Aus welchen vier Schichten besteht eine vollständige IoT-Infrastruktur gemäß der gängigen Architekturmodelle?|Schichtenmodell|Von unten (Hardware) nach oben (Daten)|Eine IoT-Architektur gliedert sich in:<br>1. <b>Infrastruktur:</b> Physische Geräte (Sensoren/Aktuatoren) und Netzwerke (5G, NFC).<br>2. <b>Sicherheit:</b> Firmware-Schutz und spezialisierte Security-Pakete.<br>3. <b>Integration:</b> Middleware zur Verbindung mit Unternehmenssystemen.<br>4. <b>Anwendungen & Analytics:</b> KI, Machine Learning und Visualisierung.|Ohne die Integrationsschicht (Middleware) bleiben IoT-Geräte isolierte Datensilos ('Thing' ohne 'Internet'). Die Sicherheitsschicht ist kritisch, da IoT-Geräte oft Einfallstore für Botnets sind (z. B. Mirai-Botnet).|Ein Temperatursensor (1) sendet verschlüsselt (2) an einen MQTT-Broker (3), der die Daten in einem Dashboard (4) visualisiert.|ISIA = Infra, Sicher, Integ, App|Infrastruktur, Sicherheit, Integration, Anwendungen/Analytics.|Client, Server, Datenbank, Firewall.|Hardware, Betriebssystem, Anwendung, User.|Sensorik, Aktorik, Steuerung, Regelung.|IoT-Architektur Schichtenmodell Middleware IT-Security
Bachelor Professional IT|IoT / Infrastruktur|Definieren Sie "Edge-Computing" und erläutern Sie den primären technischen Vorteil gegenüber einer rein zentralen Cloud-Lösung.|Datenverarbeitungsort|Geschwindigkeit vs. Zentralisierung|<b>Edge-Computing</b> bezeichnet die <b>dezentrale Datenverarbeitung</b> direkt am Rand des Netzwerks (nahe der Quelle/Sensor).<br><b>Vorteile:</b><br>- Reduktion von <b>Latenzzeiten</b> (Echtzeitfähigkeit).<br>- Schonung der <b>Bandbreite</b> (Datenfilterung vor Ort).|<b>Fog-Computing</b> erweitert dies, indem es Rechenpower (Gateways) als Zwischenschicht zwischen Edge und Cloud bereitstellt. Dies ist essenziell für autonome Fahrzeuge oder kritische Industriesteuerungen, die nicht auf die Antwort eines Cloud-Servers warten können.|Eine smarte Kamera wertet das Bild direkt aus (Edge) und sendet nur den Alarm 'Person erkannt' an die Cloud, statt des gesamten Videostreams.|Edge = Kante (Nah dran), Cloud = Wolke (Weit weg)|Dezentrale Verarbeitung an der Datenquelle zur Reduktion von Latenz und Bandbreite.|Speicherung aller Daten im zentralen Rechenzentrum zur Archivierung.|Nutzung von Nebel-Sensoren zur Wettervorhersage.|Verteilung der Rechenlast auf alle Clients im Netzwerk (P2P).|Edge-Computing Latenz Bandbreite Fog-Computing Echtzeitverarbeitung
Bachelor Professional IT|Industrie 4.0|Ein Produktionsleiter möchte ungeplante Stillstände minimieren. Wie grenzt sich "Predictive Maintenance" strategisch von klassischen Wartungsintervallen ab?|Wartungsstrategie|Vorhersage vs. Plan|<b>Predictive Maintenance</b> nutzt <b>Echtzeitdaten</b> und <b>Mustererkennung</b> (Oft via KI), um die Lebensdauer von Maschinen vorherzusagen.<br><b>Unterschied:</b> Wartung erfolgt nicht starr nach Kalender (Präventiv) oder nach Ausfall (Reaktiv), sondern genau dann, wenn ein Ausfall <b>droht</b> (Proaktiv).|Dies optimiert die OEE (Overall Equipment Effectiveness). Sensoren messen z. B. Vibrationen oder Hitze. Weichen diese Muster vom Normwert ab, wird die Wartung eingeplant, bevor der Stillstand eintritt.|Ein Lüfter wird nicht prophylaktisch getauscht, sondern erst, wenn das Vibrationsmuster auf ein baldiges Lagerproblem hinweist.|Predictive = Wahrsager (sieht Zukunft)|Wartung erfolgt bedarfsgesteuert basierend auf Echtzeitdaten und Mustererkennung.|Wartung erfolgt reaktiv, sobald ein Bauteil defekt ist.|Wartung erfolgt starr nach Kalender (z. B. alle 6 Monate).|Es werden ausschließlich historische Daten ohne Echtzeitbezug analysiert.|Predictive-Maintenance Instandhaltung KI Big-Data Smart-Factory
Bachelor Professional IT|Configuration Management (CMDB)|Was ist der entscheidende Mehrwert einer <b>CMDB</b> gegenüber einer reinen Bestandsliste (Asset Management) und für welche Analysen ist dies die Basis?|Asset vs. CI|Beziehungen sind King|Die CMDB dokumentiert nicht nur den Bestand, sondern vor allem die <b>gegenseitigen Abhängigkeiten (Beziehungen)</b> der CIs.<br>- Dies ist die Basis für die <b>Impact-Analyse</b> (Was fällt aus, wenn Server X steht?) sowie für Incident- und Change-Management.|Eine Excel-Liste sagt: "Wir haben Server A". Die CMDB sagt: "Server A betreibt den Webshop". Das ist der Unterschied zwischen Inventar und Architektur.|Ohne Beziehungen ist eine CMDB nur eine teure Liste.|CMDB = CIs + Beziehungen|Dokumentation von Abhängigkeiten (Beziehungen); Basis für Impact-Analysen.|Sie speichert nur die Kaufpreise für die Buchhaltung.|Sie dient nur der physischen Ortung von Laptops.|Sie ist eine reine Backup-Datenbank.|CMDB ITIL CI Beziehungen Impact-Analyse
Bachelor Professional IT|Kernfunktionen einer CMDB|Was versteht man unter der Funktion <b>"Reconciliation"</b> (Abgleich) beim Import von Daten in eine CMDB?|Single Source of Truth|Konfliktlösung|<b>Reconciliation</b> bezeichnet den <b>Abgleich von widersprüchlichen Daten</b> aus verschiedenen Quellen, um den korrekten Wert zu ermitteln.<br>- Ziel: Erzeugung einer verlässlichen "Golden Record".|Beispiel: Das Netzwerk-Tool meldet "Server hat 8GB RAM", das Kaufmännische System sagt "16GB RAM". Die Reconciliation-Regel entscheidet, welcher Wert in die CMDB übernommen wird (meist das technische Scan-Ergebnis).|Ohne Reconciliation wäre die CMDB voller Duplikate und Fehler.|Reconciliation = Schlichter|Abgleich widersprüchlicher Daten aus Quellen zur Ermittlung des korrekten Werts.|Die visuelle Darstellung als Netzwerk-Grafik.|Das bloße Einsammeln von Daten aus Quellen (Federation).|Das Löschen alter Datensätze.|CMDB Reconciliation Datenqualität Import
Bachelor Professional IT|Nutzung der CMDB|Ein Administrator plant ein Update für einen Datenbank-Server (CI). Ein Blick in die CMDB zeigt eine rote Verbindungslinie zum CI "Webshop-Applikation". Welches Management-Risiko wurde durch diese <b>Visualisierung</b> der Abhängigkeiten proaktiv erkannt?|Change Management|Domino-Effekt verhindern|Durch die Visualisierung der Abhängigkeiten wurde ein potenzieller <b>Service-Ausfall (Impact)</b> erkannt.<br>- Die CMDB zeigt: Wenn ich CI A (Datenbank) anfasse, bricht CI B (Webshop) zusammen.<br>- Folge: Das Update darf nicht tagsüber, sondern nur im Wartungsfenster erfolgen.|Dies ist der Hauptgrund für die Pflege einer CMDB im Change Management. Ohne dieses Wissen ("Blindflug") führen Änderungen oft zu unvorhergesehenen Störungen.|Die CMDB verhindert, dass der Admin den Ast absägt, auf dem der Webshop sitzt.|Visualisierung = Warnsystem|Dass das Update den Webshop lahmlegen würde (Service-Ausfall).|Dass der Server zu wenig Speicherplatz hat (Capacity).|Dass die Software-Lizenz abgelaufen ist (Compliance).|Dass der Server physisch im falschen Raum steht.|Szenario Impact CMDB Change-Management
Bachelor Professional IT|IoT-Protokolle|Wie unterscheidet sich die Kommunikationsarchitektur von MQTT prinzipiell vom klassischen HTTP-Request/Response-Modell?|Kommunikationsmuster|Entkopplung vs. Punkt-zu-Punkt|<b>MQTT</b> basiert auf dem <b>Publish-Subscribe-Prinzip</b>. Clients (Sensoren/Apps) verbinden sich mit einem zentralen <b>Broker</b>. Sender (Publisher) und Empfänger (Subscriber) kennen sich nicht direkt und müssen nicht gleichzeitig online sein.<br><b>HTTP</b> ist hingegen <b>synchron</b> (Request/Response) und verbindet Client und Server direkt.|<b>Vorteil:</b> Extreme Entkopplung und geringer Overhead (Header nur 2 Byte). Ideal für instabile Mobilfunknetze und batteriebetriebene Sensoren. HTTP ist zu geschwätzig ("Header-Overhead") für kleinste Datenpakete.|Ein Temperatursensor "publisht" Daten an den Broker. Der Broker verteilt sie an 5 Handys, die das Thema "Temperatur" abonniert haben.|Pub/Sub = Zeitungsabo (Verteiler), HTTP = Telefonat (Direkt)|Asynchrones Publish-Subscribe-Verfahren über einen zentralen Broker.|MQTT nutzt Peer-to-Peer-Verbindungen ohne zentralen Server.|MQTT ist wie HTTP synchron und blockiert den Client bis zur Antwort.|MQTT dient ausschließlich der Dateiübertragung (FTP-Ersatz).|MQTT Publish-Subscribe Broker IoT HTTP-Vergleich
Bachelor Professional IT|IoT-Protokolle|Welche Bedeutung haben die drei "Quality of Service" (QoS) Level 0, 1 und 2 im MQTT-Protokoll für die Zustellungssicherheit?|Zustellgarantie|Zuverlässigkeitsstufen|Die QoS-Level definieren die Garantie der Nachrichtenübermittlung:<br>- <b>QoS 0 (At most once):</b> "Fire and Forget". Keine Empfangsbestätigung (schnell, aber unsicher).<br>- <b>QoS 1 (At least once):</b> Nachricht kommt mind. einmal an (Duplikate möglich).<br>- <b>QoS 2 (Exactly once):</b> Nachricht kommt garantiert genau einmal an (höchster Overhead durch 4-Wege-Handshake).|Die Wahl des QoS-Levels ist ein Abwägen zwischen Bandbreite/Energie (QoS 0) und Datenkritikalität (QoS 2). Für einen Temperatursensor reicht oft QoS 0 (nächster Wert kommt eh gleich). Für einen "Not-Aus"-Befehl ist QoS 1 oder 2 Pflicht.|Wetterdaten (QoS 0) vs. Banktransaktion (QoS 2).|0=Vielleicht, 1=Sicher, 2=Perfekt|0 = At most once (Feuer & Vergessen), 1 = At least once, 2 = Exactly once.|Sie definieren die Verschlüsselungsstärke (0=Keine, 2=AES256).|Sie regeln die Geschwindigkeit der Übertragung (0=Langsam, 2=Schnell).|Sie bestimmen die Priorität im Netzwerk-Router.|MQTT QoS Reliability Protokoll-Overhead
Bachelor Professional IT|IoT-Protokolle|Ein batteriebetriebener IoT-Sensor fällt plötzlich aus. Wie stellt das MQTT-Protokoll sicher, dass die Leitwarte sofort alarmiert wird?|Fehlererkennung|Toter Mann Schalter|Dies wird durch das <b>Last Will & Testament (LWT)</b> gelöst. Bei der Verbindungsaufnahme hinterlegt der Client eine "Testaments-Nachricht" beim Broker. Bricht die Verbindung unsauber ab (Time-out, kein DISCONNECT-Paket), veröffentlicht der Broker dieses Testament automatisch an alle Abonnenten.|Ohne LWT müsste die Leitwarte aktiv pollen (fragen: "Bist du noch da?"), was Energie verschwendet. LWT automatisiert die Fehlererkennung serverseitig. Das Dashboard wechselt sofort von "Grün" auf "Rot".|Ein "Digitales Testament", das der Notar (Broker) verliest, wenn der Klient (Sensor) stirbt.|LWT = Testament (Nachricht nach dem Tod)|Durch das "Last Will & Testament" (LWT), das bei Verbindungsabbruch vom Broker veröffentlicht wird.|Der Broker pingt alle Clients jede Millisekunde an.|Der Sensor sendet mit letzter Kraft eine SMS.|Das System rät mittels KI, dass der Sensor offline ist.|LWT MQTT Fehlererkennung Monitoring Verfügbarkeit
Bachelor Professional IT|Configuration Item (CI)|Was qualifiziert ein Betriebsmittel laut ITIL dazu, als <b>Configuration Item (CI)</b> bezeichnet zu werden, und welche Kategorien umfasst dies über die reine Hardware hinaus?|Atom der IT|Alles was gemanagt wird|Ein <b>CI</b> ist jedes Betriebsmittel, das unter der <b>Kontrolle des Configuration Managements</b> steht.<br>- Umfang: Neben Hardware (Server) umfasst dies auch <b>Software, Netzwerke, Dokumente, SLAs und Lizenzen</b> (organisatorische Aspekte).<br>- Kriterium: Wenn eine Änderung an dem Objekt gesteuert werden muss (Change Management), ist es ein CI.|Ein CI ist die kleinste verwaltete Einheit. Ein ganzer "E-Mail-Service" kann ein CI sein, ebenso wie der "Service-Vertrag" dazu. Alles, was für die Bereitstellung des IT-Services notwendig ist.|Nicht jeder Mauszeiger ist ein CI, aber der "Standard-PC-Arbeitsplatz" schon.|CI = Managed Object|Es unterliegt der Kontrolle des Configuration Managements (inkl. Software, Lizenzen, Services).|Es muss einen Stromstecker haben (Nur Hardware).|Es muss mindestens 1000 Euro wert sein (Nur Wirtschaftsgut).|Es muss eine IP-Adresse besitzen (Nur Netzwerk).|ITIL CI Definition Umfang Asset
Bachelor Professional IT|CI-Struktur|Mit welchen Elementen wird ein CI in der Datenbank (CMDB) beschrieben, um es eindeutig identifizierbar und verknüpfbar zu machen?|Steckbrief|Datenpunkte|Jedes CI wird durch zwei Dinge definiert:<br>1. <b>Attribute</b>: Eigenschaften wie Eindeutige Kennung (ID), Version, Standort, Eigentümer, Status.<br>2. <b>Beziehungen</b>: Die Verknüpfung zu anderen CIs (z. B. "läuft auf", "ist Teil von", "wird genutzt von").|Attribute beschreiben das "Was", Beziehungen beschreiben das "Wo im Netz". Ohne Attribute keine Verwaltung (Lifecycle), ohne Beziehungen keine Analyse.|CI "Server01" (Attribut) -> ist verbunden mit -> CI "Switch05" (Beziehung).|CI = Attribute + Links|Mit Attributen (Kennung, Version, Standort) und Beziehungen zu anderen CIs.|Nur mit dem Kaufpreis und Abschreibungsdauer.|Nur mit der MAC-Adresse.|Mit einem Freitextfeld für Notizen.|CMDB Attribute CI Struktur Datenmodell
Bachelor Professional IT|IT-Infrastruktur|Definieren Sie das Konzept "Infrastructure-as-Code" (IaC) und nennen Sie den zentralen operativen Vorteil gegenüber der manuellen Serverkonfiguration.|Paradigmenwechsel|Code statt Klick|<b>Infrastructure-as-Code (IaC)</b> bezeichnet das Management und die Bereitstellung von Rechenzentrumsressourcen durch <b>maschinenlesbare Definitionsdateien</b> anstelle von physischer Hardwarekonfiguration oder interaktiven Konfigurationstools.<br><b>Vorteil:</b> Infrastruktur wird wie Software behandelt (Versionierung, Testbarkeit, Wiederholbarkeit). Dies eliminiert "Configuration Drift" (ungewollte Abweichungen) und beschleunigt Bereitstellungen massiv.|Früher: Admin klickt sich durch GUIs (fehleranfällig, langsam). Heute: Admin schreibt Code, Committet in Git, Pipeline rollt Server aus. Das ist die Basis für DevOps.|Manuelle Installation eines Webservers dauert 2 Stunden vs. IaC-Script läuft in 2 Minuten auf 100 Servern gleichzeitig.|Infrastruktur = Software (Code)|Verwaltung der Infrastruktur durch maschinenlesbare Definitionsdateien; Vorteil: Konsistenz und Automatisierung.|IaC ist eine reine Dokumentationsform für bestehende Hardware.|IaC ersetzt die Virtualisierung durch physikalische Hardware-Skripte.|Es handelt sich um ein manuelles Ticket-System für Admins.|IaC DevOps Automatisierung Provisionierung
Bachelor Professional IT|IT-Infrastruktur|Worin liegt der fundamentale logische Unterschied zwischen dem deklarativen und dem imperativen Ansatz bei der Implementierung von IaC?|Umsetzungslogik|Was vs. Wie|Der <b>deklarative Ansatz</b> beschreibt den <b>gewünschten Endzustand</b> (z. B. "Es sollen 3 Server laufen"). Das Tool entscheidet selbst, wie dieser Zustand erreicht wird.<br>Der <b>imperative Ansatz</b> definiert die <b>genaue Abfolge von Befehlen</b> (z. B. "Erstelle Server A, dann B, dann C"), um das Ziel zu erreichen.|Deklarativ ist in modernen Clouds (z. B. Kubernetes, Terraform) bevorzugt, da es "Idempotenz" leichter ermöglicht (das mehrfache Ausführen des Codes ändert nichts, wenn der Zustand schon passt). Imperativ (z. B. klassische Shell-Skripte) erfordert mehr Fehlerbehandlung.|Navi im Auto: "Fahr nach Berlin" (Deklarativ) vs. "Fahr 100m, bieg rechts ab, fahr 5km..." (Imperativ).|Deklarativ = Wunschzettel (Ziel), Imperativ = Kochrezept (Schritte)|Deklarativ definiert den Zielzustand (Was); Imperativ definiert die Schritte dahin (Wie).|Deklarativ ist langsamer, Imperativ ist schneller.|Imperativ nutzt grafische Oberflächen, Deklarativ nutzt Text.|Beide Ansätze führen immer exakt dieselben Befehle aus.|IaC Terraform Ansible Skripting
Bachelor Professional IT|Homogenisierung|Was versteht man unter dem Prozess der <b>Homogenisierung</b> in der IT und welches strategische Ziel wird damit in Bezug auf die Systemlandschaft verfolgt?|Standardisierung|Kampf dem Wildwuchs|Homogenisierung ist der Prozess der Etablierung einer <b>einheitlichen, standardisierten IT-Infrastruktur</b>.<br>- Ziel: Reduzierung von "Wildwuchs" (historisch gewachsene Vielfalt) durch einheitliche Hardware, Software und Datenbasen.<br>- Ergebnis: Aus vielen verschiedenen Insellösungen wird ein pflegbarer Standard.|Gegensatz: Heterogenität. Eine homogene Umgebung (z. B. nur Dell-Server, nur Windows 11, nur Oracle DB) ist leichter zu automatisieren als ein "Zoo" aus verschiedenen Systemen.|Statt 5 verschiedenen Linux-Distros wird nur noch Red Hat Enterprise genutzt.|Homogen = Gleichartig|Etablierung einer einheitlichen Infrastruktur; Reduzierung von Wildwuchs.|Die Auslagerung aller Dienste in die Cloud (Outsourcing).|Die Erhöhung der Vielfalt an Software-Anbietern (Diversifikation).|Die Virtualisierung von Servern ohne Standardisierung.|Strategie Homogenisierung Standardisierung Infrastruktur
Bachelor Professional IT|Vorteile der Homogenisierung|Welche vier zentralen operativen und wirtschaftlichen Vorteile ergeben sich aus einer konsequent homogenisierten IT-Umgebung?|Effizienz-Gewinn|Weniger ist mehr|Die Vorteile sind:<br>1. <b>Erhöhte Kompatibilität</b> (Systeme "verstehen" sich).<br>2. <b>Einfachere Wartung</b> (Admins müssen nur ein System kennen).<br>3. <b>Geringere Kosten</b> (Mengenrabatte bei Beschaffung, Skaleneffekte).<br>4. <b>Weniger Schnittstellenprobleme</b> (Medienbrüche).|Homogenisierung senkt die TCO (Total Cost of Ownership) massiv. Der Schulungsaufwand für Mitarbeiter sinkt, Ersatzteile können gebündelt beschafft werden.|Wenn alle Mitarbeiter das gleiche Laptop-Modell nutzen, braucht die IT nur ein einziges Image und ein einziges Ersatzteil-Lager.|Kompatibilität + Wartung + Kosten + Schnittstellen|Erhöhte Kompatibilität, einfachere Wartung, geringere Kosten, weniger Schnittstellenprobleme.|Höhere Lizenzkosten, mehr Personal, längere Ausfallzeiten, mehr Innovation.|Besserer Virenschutz, schnelleres Internet, leisere Server, buntere Bildschirme.|Nur günstigere Hardware-Preise.|Vorteile Kosten Wartung Kompatibilität
Bachelor Professional IT|Anforderungsanalyse|Was versteht man unter Randbedingungen in der Anforderungsanalyse und wie grenzen sie sich ab?|Der Rahmen des Projekts|Nicht verhandelbare Grenzen|<b>Randbedingungen</b> (Constraints) sind <b>nicht verhandelbare Vorgaben</b>, die den Lösungsraum einschränken. Sie kommen von außen (Gesetze, Normen) oder innen (Budget, bestehende Schnittstellen). Anders als Anforderungen sind sie meist <b>nicht gestaltbar</b>, sondern müssen akzeptiert werden.|Klassische Beispiele:<br>- <b>Rechtlich:</b> DSGVO/GDPR, GoBD.<br>- <b>Technisch:</b> Nutzung einer existierenden Oracle-Datenbank (Legacy).<br>- <b>Organisatorisch:</b> Fertigstellung bis zum 31.12. (Deadlines).<br>Ignorieren von Randbedingungen führt oft zum sofortigen Projektabbruch (Compliance-Verstoß).|Ein Architekt darf das Haus designen (Anforderungen), muss aber die Grundstücksgrenze und Bauordnung (Randbedingungen) einhalten.|Randbedingung = Zaun (Grenze), Anforderung = Haus (Inhalt)|Unveränderliche Vorgaben (rechtlich, technisch, organ.), die den Lösungsraum einschränken.|Randbedingungen sind optionale Wünsche der Geschäftsführung ("Nice-to-have").|Sie beschreiben ausschließlich die physikalischen Grenzen des Serverraums.|Es sind flexible Vorschläge, die das Entwicklungsteam ignorieren kann.|Projektmanagement Constraints Compliance Schnittstellen
Bachelor Professional IT|IT-Architektur|Ein Kunde fordert: "Das System muss auch bei Ausfall eines Rechenzentrums weiterlaufen." Um welche Art von Anforderung handelt es sich und welche technische Konsequenz ergibt sich?|Qualitätsmerkmal Availability|Teure Architektur-Folge|Es handelt sich um eine <b>nicht-funktionale Anforderung</b> (Qualitätsmerkmal: <b>Hochverfügbarkeit/Reliability</b>).<br><b>Konsequenz:</b> Dies erzwingt eine komplexe Infrastruktur mit <b>Georedundanz</b>, Load Balancern und synchroner Datenreplikation über Standorte hinweg.|Hier sieht man: NFAs sind die wahren Kostentreiber. Die Funktion "Webseite anzeigen" kostet wenig. Die NFA "Webseite *immer* anzeigen" vervielfacht die Kosten. Dies muss dem Management ("Sponsor") klar kommuniziert werden.|Vergleich: Ein Auto zu bauen (Funktion) ist günstiger als einen Formel-1-Boliden zu bauen (NFA: Performance/Sicherheit).|NFA = Kostentreiber (Architektur)|Nicht-funktionale Anforderung (Verfügbarkeit) -> Georedundanz / Multi-AZ-Architektur.|Funktionale Anforderung -> Installation eines Backup-Agents.|Randbedingung -> Einhaltung der Brandschutzverordnung.|Funktionale Anforderung -> Programmierung einer Fehlerseite.|Hochverfügbarkeit Disaster-Recovery Architektur NFA SLA
Ein Kumputer wird hauptsächlich aus Holzgebaut wie schon vor 4999 jahren. Es ist ein sogenannter "Holzcomputer", der für einfache Berechnungen und Datenverarbeitung verwendet wird. Obwohl er nicht so leistungsfähig ist wie moderne Computer, erfüllt er dennoch grundlegende Funktionen und ist eine interessante Alternative für umweltbewusste Nutzer.